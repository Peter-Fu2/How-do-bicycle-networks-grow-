{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import operator\n",
    "import pylab\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "from IPython.display import Image\n",
    "from pprint import pprint\n",
    "import folium\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robustness_analysis(g, node_classifier, recalculate=False):\n",
    "    m = node_classifier(g)\n",
    "    l = sorted(m.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    \n",
    "    sbg = [g.subgraph(c).copy() for c in nx.connected_components(g)]\n",
    "    largest_component = max(sbg, key=lambda c: sum(d[\"length\"] for u, v, d in c.edges(data=True)))\n",
    "    \n",
    "    \n",
    "    n = len(g.nodes())\n",
    "    tl=sum(d[\"length\"] for u, v, d in g.edges(data=True))\n",
    "    x.append(0)\n",
    "    y.append(sum(d[\"length\"] for u, v, d in largest_component.edges(data=True)) * 1. / tl)\n",
    "    r = 0.0\n",
    "    for i in range(1, n-1):\n",
    "        g.remove_node(l.pop(0)[0])\n",
    "        if recalculate:\n",
    "            m = node_classifier(g)\n",
    "            l = sorted(m.items(), key=operator.itemgetter(1),reverse=True)\n",
    "            \n",
    "        sbg = [g.subgraph(c).copy() for c in nx.connected_components(g)]\n",
    "        largest_component = max(sbg, key=lambda c: sum(d[\"length\"] for u, v, d in c.edges(data=True)))        \n",
    "        x.append(i * 1. / n)\n",
    "        r += sum(d[\"length\"] for u, v, d in largest_component.edges(data=True)) * 1. / tl\n",
    "        y.append(sum(d[\"length\"] for u, v, d in largest_component.edges(data=True)) * 1. / tl)\n",
    "    print(r,tl,n)\n",
    "    return x, y, r / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robustness_analysis_apl(g, node_classifier, recalculate=False):\n",
    "    m = node_classifier(g)\n",
    "    l = sorted(m.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    average_path_length = 0.0\n",
    "    number_of_components = 0\n",
    "    n = len(g.nodes())\n",
    "    \n",
    "    \n",
    "    \n",
    "    sbg = [g.subgraph(c).copy() for c in nx.connected_components(g)]\n",
    "    for sg in sbg:\n",
    "        average_path_length += nx.average_shortest_path_length(sg)\n",
    "        number_of_components += 1\n",
    "\n",
    "    average_path_length = average_path_length / number_of_components\n",
    "    initial_apl = average_path_length\n",
    "\n",
    "    x.append(0)\n",
    "    y.append(average_path_length * 1. / initial_apl)\n",
    "    r = 0.0\n",
    "    for i in range(1, n-1):\n",
    "        g.remove_node(l.pop(0)[0])\n",
    "        if recalculate:\n",
    "            m = node_classifier(g)\n",
    "            l = sorted(m.items(), key=operator.itemgetter(1),\n",
    "                       reverse=True)\n",
    "\n",
    "        average_path_length = 0.0\n",
    "        number_of_components = 0\n",
    "\n",
    "        \n",
    "        \n",
    "        sbg = [g.subgraph(c).copy() for c in nx.connected_components(g)]\n",
    "        for sg in sbg:\n",
    "            if len(sg.nodes()) > 1:\n",
    "                average_path_length += nx.average_shortest_path_length(sg)\n",
    "            number_of_components += 1\n",
    "\n",
    "        average_path_length = average_path_length / number_of_components\n",
    "\n",
    "        x.append(i * 1. / n)\n",
    "        r += average_path_length * 1. / initial_apl\n",
    "        y.append(average_path_length * 1. / initial_apl)\n",
    "    return x, y, r / n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def random_ranking(g):\n",
    "    nodes = g.nodes()\n",
    "    values = g.nodes()\n",
    "    values = list(values)\n",
    "    random.shuffle(values)    \n",
    "    \n",
    "    return dict(zip(nodes, values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seeds(G_bike, G_drive, pairs):\n",
    "    \"\"\"Get x pairs of random pairs of nodes in the bike and street layer.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G_bike : type\n",
    "        Description of parameter `G_bike`.\n",
    "    G_drive : type\n",
    "        Description of parameter `G_drive`.\n",
    "    pairs : type\n",
    "        Description of parameter `pairs`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    type\n",
    "        Description of returned object.\n",
    "\n",
    "    \"\"\"\n",
    "    seeds_bike = []\n",
    "    seeds_car = []\n",
    "    u = 0\n",
    "    for u in range(pairs):\n",
    "        i = random.choice(list(G_bike.nodes(data=True)))\n",
    "        j = random.choice(list(G_bike.nodes(data=True)))\n",
    "        u = ox.distance.nearest_nodes(G_drive, i[1]['x'], i[1]['y'])\n",
    "        v = ox.distance.nearest_nodes(G_drive, j[1]['x'], j[1]['y'])\n",
    "        if u != v or i[0] != j[0]:\n",
    "            seeds_car.append((u, v))\n",
    "            seeds_bike.append((i[0], j[0]))\n",
    "        else:\n",
    "            i = random.choice(list(G_bike.nodes(data=True)))\n",
    "            j = random.choice(list(G_bike.nodes(data=True)))\n",
    "            u = ox.distance.nearest_nodes(G_drive,  i[1]['x'], i[1]['y'])\n",
    "            v = ox.distance.nearest_nodes(G_drive,  j[1]['x'], j[1]['y'])\n",
    "    return seeds_bike, seeds_car\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#euclidean distance\n",
    "def euclidean_dist_vec(y1, x1, y2, x2):\n",
    "    '''\n",
    "    Calculate the euclidean distance between two points.\n",
    "    '''\n",
    "    \n",
    "    #distance = ((x1 - x2) ** 2 + (y1 - y2) ** 2) ** 0.5  #use this one if the graph is projected\n",
    "    distance = ox.distance.great_circle_vec(y1, x1, y2, x2)  #use this one if the graph is not projected\n",
    "    #print('euclidean distance=',distance)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shortest path\n",
    "def get_travel_distance(G, u_v):\n",
    "    \"\"\"Find the shortest path between two nodes and calculate the travel distance.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    G : nx.Graph\n",
    "        Networkx graph.\n",
    "    u_v : touple\n",
    "        Touple containing the origin and destination for the path.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        Distance for the path between 'u' to 'v'.\n",
    "\n",
    "    \"\"\"\n",
    "    path = nx.shortest_path(G, u_v[0], u_v[1], weight='length')\n",
    "    distance = 0\n",
    "    for i, j in zip(path[:-1], path[1:]):\n",
    "        #distance += float(G[i][j][0]['length'])\n",
    "        try:\n",
    "            distance += float(G[i][j][0]['length'])\n",
    "        except:\n",
    "            distance += euclidean_dist_vec(G.nodes[i]['y'], G.nodes[i]['x'], G.nodes[j]['y'], G.nodes[j]['x'])\n",
    "            print('Error: {} {}, distance: {}'.format(G, u_v,euclidean_dist_vec(G.nodes[i]['y'],G.nodes[i]['x'], G.nodes[j]['y'], G.nodes[j]['x'])))\n",
    "    #print('travel distance=',distance)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_directness(G_bike, G_drive, name, seeds_bike, car_value):\n",
    "    d_ij_b = []\n",
    "    d_ij_s = []\n",
    "    print('Calculating {}'.format(name))\n",
    "    try:\n",
    "        G_bike.add_edge(int(row['i']), int(row['j']), length=euclidean_dist_vec(G_bike.nodes[row['i']]['y'],G_bike.nodes[row['i']]['x'], G_bike.nodes[row['j']]['y'], G_bike.nodes[row['j']]['x']))\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "        avg_bike = [] \n",
    "        for i_j in seeds_bike:\n",
    "            if nx.has_path(G_bike, i_j[0], i_j[1]):\n",
    "                euclidean_distance = euclidean_dist_vec(G_bike.nodes[i_j[0]]['y'], G_bike.nodes[i_j[0]]['x'], G_bike.nodes[i_j[1]]['y'], G_bike.nodes[i_j[0]]['x'])\n",
    "                bike_distance = get_travel_distance(G_bike, i_j)\n",
    "                #avg_bike.append(euclidean_distance)\n",
    "                avg_bike.append(euclidean_distance/bike_distance)\n",
    "            else:\n",
    "                avg_bike.append(0)\n",
    "        bike_value = np.average(avg_bike)\n",
    "        d_ij_b.append(bike_value)\n",
    "        d_ij_s.append(car_value)\n",
    "        #print('bike_distance=',bike_distance)\n",
    "        print('{} Efficiency: {}/{}'.format(name, round(bike_value, 3), round(car_value, 3)))\n",
    "        \n",
    "    #print('Efficiency: {}/{}'.format(round(bike_value, 3), round(car_value, 3)))\n",
    "    return d_ij_b, G_bike\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ox.config(log_console=True, use_cache=True,overpass_settings='[out:json][timeout:180][date:\"2021-04-01T00:00:00Z\"]')\n",
    "\n",
    "\n",
    "\n",
    "cf1 = '[\"highway\"~\"cycleway\"][\"bicycle\"!~\"no\"]'\n",
    "cf2 = '[\"cycleway\"][\"cycleway\"!~\"no\"]'\n",
    "cf3 = '[\"cycleway:right\"][\"cycleway:right\"!~\"no\"]'\n",
    "cf4 = '[\"cycleway:left\"][\"cycleway:left\"!~\"no\"]'\n",
    "cf5 = '[\"cycleway:both\"][\"cycleway:both\"!~\"no\"]'\n",
    "cf6 = '[\"bicycle\"~\"designated\"]'\n",
    "cf7 = '[\"oneway:bicycle\"]'\n",
    "\n",
    "bbox1 = (45.4976,45.46148,9.2253,9.1642)\n",
    "\n",
    "G_21_1 = ox.graph.graph_from_bbox(45.4976,45.46148,9.2253,9.1642,  simplify=False, retain_all=True, truncate_by_edge=False, clean_periphery=True, custom_filter=cf1)\n",
    "G_21_2 = ox.graph.graph_from_bbox(45.4976,45.46148,9.2253,9.1642,  simplify=False, retain_all=True, truncate_by_edge=False, clean_periphery=True, custom_filter=cf2)\n",
    "G_21_3 = ox.graph.graph_from_bbox(45.4976,45.46148,9.2253,9.1642,  simplify=False, retain_all=True, truncate_by_edge=False, clean_periphery=True, custom_filter=cf3)\n",
    "G_21_4 = ox.graph.graph_from_bbox(45.4976,45.46148,9.2253,9.1642,  simplify=False, retain_all=True, truncate_by_edge=False, clean_periphery=True, custom_filter=cf4)\n",
    "G_21_5 = ox.graph.graph_from_bbox(45.4976,45.46148,9.2253,9.1642,  simplify=False, retain_all=True, truncate_by_edge=False, clean_periphery=True, custom_filter=cf5)\n",
    "G_21_6 = ox.graph.graph_from_bbox(45.4976,45.46148,9.2253,9.1642,  simplify=False, retain_all=True, truncate_by_edge=False, clean_periphery=True, custom_filter=cf6)\n",
    "G_21_7 = ox.graph.graph_from_bbox(45.4976,45.46148,9.2253,9.1642,  simplify=False, retain_all=True, truncate_by_edge=False, clean_periphery=True, custom_filter=cf7)\n",
    "\n",
    "\n",
    "\n",
    "G_21_11 = nx.compose(G_21_1,  G_21_2)\n",
    "G_21_12 = nx.compose(G_21_11, G_21_3)\n",
    "G_21_13 = nx.compose(G_21_12, G_21_4)\n",
    "G_21_14 = nx.compose(G_21_13, G_21_5)\n",
    "G_21_15 = nx.compose(G_21_14, G_21_6)\n",
    "G_21_16 = nx.compose(G_21_15, G_21_7)\n",
    "\n",
    "G_21_21 = ox.simplification.consolidate_intersections(ox.project_graph(G_21_16,to_crs='EPSG:3812'), tolerance=15, rebuild_graph=True, dead_ends=True, reconnect_edges=True)\n",
    "G_21_22 = ox.project_graph(G_21_21, to_crs='EPSG:4326')\n",
    "\n",
    "fig, axb1 = ox.plot_graph(G_21_22, node_size=0,bgcolor='black',edge_color='red',edge_linewidth=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ox.config(log_console=True, use_cache=True,overpass_settings='[out:json][timeout:180][date:\"2020-01-01T00:00:00Z\"]')\n",
    "\n",
    "\n",
    "\n",
    "cf1 = '[\"highway\"~\"cycleway\"][\"bicycle\"!~\"no\"]'\n",
    "cf2 = '[\"cycleway\"][\"cycleway\"!~\"no\"]'\n",
    "cf3 = '[\"cycleway:right\"][\"cycleway:right\"!~\"no\"]'\n",
    "cf4 = '[\"cycleway:left\"][\"cycleway:left\"!~\"no\"]'\n",
    "cf5 = '[\"cycleway:both\"][\"cycleway:both\"!~\"no\"]'\n",
    "cf6 = '[\"bicycle\"~\"designated\"]'\n",
    "cf7 = '[\"oneway:bicycle\"]'\n",
    "\n",
    "bbox1 = (45.4976,45.46148,9.2253,9.1642)\n",
    "\n",
    "G_20_1 = ox.graph.graph_from_bbox(45.4976,45.46148,9.2253,9.1642,  simplify=False, retain_all=True, truncate_by_edge=False, clean_periphery=True, custom_filter=cf1)\n",
    "G_20_2 = ox.graph.graph_from_bbox(45.4976,45.46148,9.2253,9.1642,  simplify=False, retain_all=True, truncate_by_edge=False, clean_periphery=True, custom_filter=cf2)\n",
    "G_20_3 = ox.graph.graph_from_bbox(45.4976,45.46148,9.2253,9.1642,  simplify=False, retain_all=True, truncate_by_edge=False, clean_periphery=True, custom_filter=cf3)\n",
    "G_20_4 = ox.graph.graph_from_bbox(45.4976,45.46148,9.2253,9.1642,  simplify=False, retain_all=True, truncate_by_edge=False, clean_periphery=True, custom_filter=cf4)\n",
    "G_20_6 = ox.graph.graph_from_bbox(45.4976,45.46148,9.2253,9.1642,  simplify=False, retain_all=True, truncate_by_edge=False, clean_periphery=True, custom_filter=cf6)\n",
    "G_20_7 = ox.graph.graph_from_bbox(45.4976,45.46148,9.2253,9.1642,  simplify=False, retain_all=True, truncate_by_edge=False, clean_periphery=True, custom_filter=cf7)\n",
    "\n",
    "G_20_11 = nx.compose(G_20_1,  G_20_2)\n",
    "G_20_12 = nx.compose(G_20_11, G_20_3)\n",
    "G_20_13 = nx.compose(G_20_12, G_20_4)\n",
    "G_20_15 = nx.compose(G_20_13, G_20_6)\n",
    "G_20_16 = nx.compose(G_20_15, G_20_7)\n",
    "\n",
    "G_20_21 = ox.simplification.consolidate_intersections(ox.project_graph(G_20_16,to_crs='EPSG:3812'), tolerance=15, rebuild_graph=True, dead_ends=True, reconnect_edges=True)\n",
    "G_20_22 = ox.project_graph(G_20_21, to_crs='EPSG:4326')\n",
    "\n",
    "fig, axb2 = ox.plot_graph(G_20_22, node_size=0,bgcolor='black',edge_color='white',edge_linewidth=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 2020-01-01 car networks(.graphml file) of Milano\n",
    "\n",
    "ox.config(overpass_settings='[out:json][timeout:180][date:\"2021-04-01T00:00:00Z\"]')\n",
    "\n",
    "\n",
    "bbox1 = (45.4976,45.46148,9.2253,9.1642)\n",
    "\n",
    "G_21_d1 = ox.graph.graph_from_bbox(45.4976,45.46148,9.2253,9.1642,  network_type='drive',simplify=False, retain_all=False, \n",
    "                                  truncate_by_edge=False, clean_periphery=True, custom_filter=None)\n",
    "\n",
    "\n",
    "\n",
    "#ox.io.save_graphml(G_20_d3, filepath='data_indicator/Milano/Milano_20_drive.graphml', gephi=False, encoding='utf-8')\n",
    "print('Milano 21_drive_net saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get 2020-01-01 car networks(.graphml file) of Milano\n",
    "\n",
    "ox.config(overpass_settings='[out:json][timeout:180][date:\"2020-01-01T00:00:00Z\"]')\n",
    "\n",
    "\n",
    "bbox1 = (45.4976,45.46148,9.2253,9.1642)\n",
    "\n",
    "G_20_d1 = ox.graph.graph_from_bbox(45.4976,45.46148,9.2253,9.1642,  network_type='drive',simplify=False, retain_all=False, \n",
    "                                  truncate_by_edge=False, clean_periphery=True, custom_filter=None)\n",
    "\n",
    "\n",
    "\n",
    "#ox.io.save_graphml(G_20_d3, filepath='data_indicator/Milano/Milano_20_drive.graphml', gephi=False, encoding='utf-8')\n",
    "print('Milano 20_drive_net saved')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the network efficiency(connectedness) of networks (table 5.1)\n",
    "\n",
    "g = ox.utils_graph.get_digraph(G_21_21, weight='length')\n",
    "g_21 = g.to_undirected()\n",
    "\n",
    "n = len(g_21)\n",
    "denom = n * (n - 1)\n",
    "if denom != 0:\n",
    "    lengths = nx.all_pairs_dijkstra_path_length(g_21, weight=\"weight\")\n",
    "    g_eff = 0\n",
    "    for source, targets in lengths:\n",
    "        for target, distance in targets.items():\n",
    "            if distance > 0:\n",
    "                g_eff += (1 / distance)\n",
    "    g_eff /= denom\n",
    "    # g_eff = sum(1 / d for s, tgts in lengths\n",
    "    #                   for t, d in tgts.items() if d > 0) / denom\n",
    "else:\n",
    "    g_eff = 0\n",
    "    \n",
    "print('eff of 21 Milano {}'.format(g_eff))\n",
    "\n",
    "g = ox.utils_graph.get_digraph(G_20_21, weight='length')\n",
    "g_20 = g.to_undirected()\n",
    "\n",
    "n = len(g_20)\n",
    "denom = n * (n - 1)\n",
    "if denom != 0:\n",
    "    lengths = nx.all_pairs_dijkstra_path_length(g_20, weight=\"weight\")\n",
    "    g_eff = 0\n",
    "    for source, targets in lengths:\n",
    "        for target, distance in targets.items():\n",
    "            if distance > 0:\n",
    "                g_eff +=( 1 / distance)\n",
    "    g_eff /= denom\n",
    "    # g_eff = sum(1 / d for s, tgts in lengths\n",
    "    #                   for t, d in tgts.items() if d > 0) / denom\n",
    "else:\n",
    "    g_eff = 0\n",
    "    \n",
    "print('eff of 20 Milano {}'.format(g_eff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,6):\n",
    "\n",
    "    # calculate the directness and connectedness of 2021 bike networks of Milano\n",
    "    '''\n",
    "    Right now there is a bug about loading .graphml file which is saved from intersections consolidated graph, \n",
    "    so the graph has to be used at once. But the bug was recently fixed and will appear in the next release, \n",
    "    targeted for early May 2021, just right after the paper written. So maybe graphs can be gotten by: \n",
    "\n",
    "    G_bike = ox.load_graphml('data_indicator/Milano/Milano_21_bike.graphml')\n",
    "\n",
    "\n",
    "    '''\n",
    "    print('calculating indicators of 2021 bike')\n",
    "\n",
    "    seeds = 1000# how many node pairs are going to be chosen\n",
    "\n",
    "    G_drive = G_21_d1\n",
    "    G_drive = ox.get_undirected(G_drive)\n",
    "\n",
    "    avg_street = []\n",
    "    avg_street_1=[]\n",
    "    avg_street_2=[]\n",
    "    G_bike = G_21_16\n",
    "    G_bike = ox.get_undirected(G_bike)   \n",
    "    seeds_bike, seeds_car = get_seeds(G_bike, G_drive, seeds) \n",
    "    for u_v in seeds_car:\n",
    "        euclidean_distance = euclidean_dist_vec(G_drive.nodes[u_v[0]]['y'],G_drive.nodes[u_v[0]]['x'], G_drive.nodes[u_v[1]]['y'], G_drive.nodes[u_v[0]]['x'])\n",
    "        travel_distance = get_travel_distance(G_drive, u_v)\n",
    "        if travel_distance==0:\n",
    "            euclidean_distance=0.0\n",
    "            travel_distance=1.0\n",
    "        else:\n",
    "            result=travel_distance\n",
    "            avg_street.append(euclidean_distance/travel_distance)\n",
    "\n",
    "\n",
    "    car_value = np.average(avg_street)  # Average efficiency in the car layer\n",
    "    d_ij_b, G_bike = calculate_directness(G_bike, G_drive, 'Milano', seeds_bike, car_value)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,6):\n",
    "    # calculate the directness and connectedness of 2020 bike networks of Milano\n",
    "    '''\n",
    "    Right now there is a bug about loading .graphml file which is saved from intersections consolidated graph, \n",
    "    so the graph has to be used at once. But the bug was recently fixed and will appear in the next release, \n",
    "    targeted for early May 2021, just right after the paper written. So maybe graphs can be gotten by: \n",
    "\n",
    "    G_bike = ox.load_graphml('data_indicator/Milano/Milano_20_bike.graphml')\n",
    "\n",
    "\n",
    "    '''\n",
    "    print('calculating indicators of 2020 bike')\n",
    "\n",
    "    seeds = 1000# how many node pairs are going to be chosen\n",
    "\n",
    "    G_drive = G_20_d1\n",
    "    G_drive = ox.get_undirected(G_drive)\n",
    "\n",
    "    avg_street = []\n",
    "    avg_street_1=[]\n",
    "    avg_street_2=[]\n",
    "    G_bike = G_20_16\n",
    "    G_bike = ox.get_undirected(G_bike)   \n",
    "    seeds_bike, seeds_car = get_seeds(G_bike, G_drive, seeds) \n",
    "    for u_v in seeds_car:\n",
    "        euclidean_distance = euclidean_dist_vec(G_drive.nodes[u_v[0]]['y'],G_drive.nodes[u_v[0]]['x'], G_drive.nodes[u_v[1]]['y'], G_drive.nodes[u_v[0]]['x'])\n",
    "        travel_distance = get_travel_distance(G_drive, u_v)\n",
    "        if travel_distance==0:\n",
    "            euclidean_distance=0.0\n",
    "            travel_distance=1.0\n",
    "        else:\n",
    "            result=travel_distance\n",
    "            avg_street.append(euclidean_distance/travel_distance)\n",
    "\n",
    "\n",
    "    car_value = np.average(avg_street)  # Average efficiency in the car layer\n",
    "    d_ij_b, G_bike = calculate_directness(G_bike, G_drive, 'Milano', seeds_bike, car_value)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d_original = ox.stats.basic_stats(G_21_16)\n",
    "print('Milano 20_d_original:\\n{}'.format(d_original))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "d_original = ox.stats.basic_stats(G_20_16)\n",
    "print('Milano 20_d_original:\\n{}'.format(d_original))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ox.config(log_console=True, use_cache=True,overpass_settings='[out:json][timeout:180][date:\"2021-04-01T00:00:00Z\"]')\n",
    "\n",
    "\n",
    "\n",
    "cf1 = '[\"highway\"~\"cycleway\"][\"bicycle\"!~\"no\"]'\n",
    "cf2 = '[\"cycleway\"][\"cycleway\"!~\"no\"]'\n",
    "cf3 = '[\"cycleway:right\"][\"cycleway:right\"!~\"no\"]'\n",
    "cf4 = '[\"cycleway:left\"][\"cycleway:left\"!~\"no\"]'\n",
    "cf5 = '[\"cycleway:both\"][\"cycleway:both\"!~\"no\"]'\n",
    "cf6 = '[\"bicycle\"~\"designated\"]'\n",
    "cf7 = '[\"oneway:bicycle\"]'\n",
    "\n",
    "bbox1 = (45.4976,45.46148,9.2253,9.1642)\n",
    "\n",
    "G_21_1 = ox.graph.graph_from_bbox(45.4976,45.46148,9.2253,9.1642,  simplify=False, retain_all=True, truncate_by_edge=False, clean_periphery=True, custom_filter=cf1)\n",
    "G_21_2 = ox.graph.graph_from_bbox(45.4976,45.46148,9.2253,9.1642,  simplify=False, retain_all=True, truncate_by_edge=False, clean_periphery=True, custom_filter=cf2)\n",
    "G_21_3 = ox.graph.graph_from_bbox(45.4976,45.46148,9.2253,9.1642,  simplify=False, retain_all=True, truncate_by_edge=False, clean_periphery=True, custom_filter=cf3)\n",
    "G_21_4 = ox.graph.graph_from_bbox(45.4976,45.46148,9.2253,9.1642,  simplify=False, retain_all=True, truncate_by_edge=False, clean_periphery=True, custom_filter=cf4)\n",
    "G_21_5 = ox.graph.graph_from_bbox(45.4976,45.46148,9.2253,9.1642,  simplify=False, retain_all=True, truncate_by_edge=False, clean_periphery=True, custom_filter=cf5)\n",
    "G_21_6 = ox.graph.graph_from_bbox(45.4976,45.46148,9.2253,9.1642,  simplify=False, retain_all=True, truncate_by_edge=False, clean_periphery=True, custom_filter=cf6)\n",
    "G_21_7 = ox.graph.graph_from_bbox(45.4976,45.46148,9.2253,9.1642,  simplify=False, retain_all=True, truncate_by_edge=False, clean_periphery=True, custom_filter=cf7)\n",
    "\n",
    "\n",
    "\n",
    "G_21_11 = nx.compose(G_21_1,  G_21_2)\n",
    "G_21_12 = nx.compose(G_21_11, G_21_3)\n",
    "G_21_13 = nx.compose(G_21_12, G_21_4)\n",
    "G_21_14 = nx.compose(G_21_13, G_21_5)\n",
    "G_21_15 = nx.compose(G_21_14, G_21_6)\n",
    "G_21_16 = nx.compose(G_21_15, G_21_7)\n",
    "G_21_16 = ox.simplification.simplify_graph(G_21_16)\n",
    "\n",
    "G_21_21 = ox.simplification.consolidate_intersections(ox.project_graph(G_21_16,to_crs='EPSG:3812'), tolerance=15, rebuild_graph=True, dead_ends=True, reconnect_edges=True)\n",
    "G_21_22 = ox.project_graph(G_21_21, to_crs='EPSG:4326')\n",
    "\n",
    "fig, axb1 = ox.plot_graph(G_21_22, node_size=0,bgcolor='black',edge_color='red',edge_linewidth=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ox.config(log_console=True, use_cache=True,overpass_settings='[out:json][timeout:180][date:\"2020-01-01T00:00:00Z\"]')\n",
    "\n",
    "\n",
    "\n",
    "cf1 = '[\"highway\"~\"cycleway\"][\"bicycle\"!~\"no\"]'\n",
    "cf2 = '[\"cycleway\"][\"cycleway\"!~\"no\"]'\n",
    "cf3 = '[\"cycleway:right\"][\"cycleway:right\"!~\"no\"]'\n",
    "cf4 = '[\"cycleway:left\"][\"cycleway:left\"!~\"no\"]'\n",
    "cf5 = '[\"cycleway:both\"][\"cycleway:both\"!~\"no\"]'\n",
    "cf6 = '[\"bicycle\"~\"designated\"]'\n",
    "cf7 = '[\"oneway:bicycle\"]'\n",
    "\n",
    "bbox1 = (45.4976,45.46148,9.2253,9.1642)\n",
    "\n",
    "G_20_1 = ox.graph.graph_from_bbox(45.4976,45.46148,9.2253,9.1642,  simplify=False, retain_all=True, truncate_by_edge=False, clean_periphery=True, custom_filter=cf1)\n",
    "G_20_2 = ox.graph.graph_from_bbox(45.4976,45.46148,9.2253,9.1642,  simplify=False, retain_all=True, truncate_by_edge=False, clean_periphery=True, custom_filter=cf2)\n",
    "G_20_3 = ox.graph.graph_from_bbox(45.4976,45.46148,9.2253,9.1642,  simplify=False, retain_all=True, truncate_by_edge=False, clean_periphery=True, custom_filter=cf3)\n",
    "G_20_4 = ox.graph.graph_from_bbox(45.4976,45.46148,9.2253,9.1642,  simplify=False, retain_all=True, truncate_by_edge=False, clean_periphery=True, custom_filter=cf4)\n",
    "G_20_6 = ox.graph.graph_from_bbox(45.4976,45.46148,9.2253,9.1642,  simplify=False, retain_all=True, truncate_by_edge=False, clean_periphery=True, custom_filter=cf6)\n",
    "G_20_7 = ox.graph.graph_from_bbox(45.4976,45.46148,9.2253,9.1642,  simplify=False, retain_all=True, truncate_by_edge=False, clean_periphery=True, custom_filter=cf7)\n",
    "\n",
    "G_20_11 = nx.compose(G_20_1,  G_20_2)\n",
    "G_20_12 = nx.compose(G_20_11, G_20_3)\n",
    "G_20_13 = nx.compose(G_20_12, G_20_4)\n",
    "G_20_15 = nx.compose(G_20_13, G_20_6)\n",
    "G_20_16 = nx.compose(G_20_15, G_20_7)\n",
    "G_20_16 = ox.simplification.simplify_graph(G_20_16)\n",
    "\n",
    "G_20_21 = ox.simplification.consolidate_intersections(ox.project_graph(G_20_16,to_crs='EPSG:3812'), tolerance=15, rebuild_graph=True, dead_ends=True, reconnect_edges=True)\n",
    "G_20_22 = ox.project_graph(G_20_21, to_crs='EPSG:4326')\n",
    "\n",
    "fig, axb2 = ox.plot_graph(G_20_22, node_size=0,bgcolor='black',edge_color='white',edge_linewidth=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g = ox.utils_graph.get_digraph(G_21_16, weight='length')\n",
    "g_21 = G_21_21.to_undirected()\n",
    "\n",
    "n = len(g_21)\n",
    "denom = n * (n - 1)\n",
    "if denom != 0:\n",
    "    lengths = nx.all_pairs_dijkstra_path_length(g_21, weight=\"weight\")\n",
    "    g_eff = 0\n",
    "    for source, targets in lengths:\n",
    "        for target, distance in targets.items():\n",
    "            if distance > 0:\n",
    "                g_eff += 1 / distance\n",
    "    g_eff /= denom\n",
    "    # g_eff = sum(1 / d for s, tgts in lengths\n",
    "    #                   for t, d in tgts.items() if d > 0) / denom\n",
    "else:\n",
    "    g_eff = 0\n",
    "    \n",
    "print('eff of 21 Milano {}'.format(g_eff))\n",
    "\n",
    "#g = ox.utils_graph.get_digraph(G_20_16, weight='length')\n",
    "g_20 = G_20_21.to_undirected()\n",
    "\n",
    "n = len(g_20)\n",
    "denom = n * (n - 1)\n",
    "if denom != 0:\n",
    "    lengths = nx.all_pairs_dijkstra_path_length(g_20, weight=\"weight\")\n",
    "    g_eff = 0\n",
    "    for source, targets in lengths:\n",
    "        for target, distance in targets.items():\n",
    "            if distance > 0:\n",
    "                g_eff += 1 / distance\n",
    "    g_eff /= denom\n",
    "    # g_eff = sum(1 / d for s, tgts in lengths\n",
    "    #                   for t, d in tgts.items() if d > 0) / denom\n",
    "else:\n",
    "    g_eff = 0\n",
    "    \n",
    "print('eff of 20 Milano {}'.format(g_eff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apl=True\n",
    "\n",
    "if apl==True:\n",
    "    analysis_method = robustness_analysis_apl\n",
    "    method='apl'\n",
    "else:\n",
    "    analysis_method = robustness_analysis\n",
    "    method='com'\n",
    "        \n",
    "outfile='data_indicator/Milano/Robustness/part2/part2_b21_{}.png'.format(method)\n",
    "\n",
    "recalculate=False\n",
    "\n",
    "g = ox.utils_graph.get_digraph(G_21_16, weight='length')\n",
    "g = g.to_undirected()\n",
    "#g = ox.utils_graph.get_undirected(G_bspf)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x1, y1, vd = analysis_method(g.copy(), nx.degree_centrality, recalculate)\n",
    "x2, y2, vb = analysis_method(g.copy(), nx.betweenness_centrality, recalculate)\n",
    "x3, y3, vc = analysis_method(g.copy(), nx.closeness_centrality, recalculate)\n",
    "x5, y5, vr = analysis_method(g.copy(), random_ranking)\n",
    "\n",
    "if not apl:\n",
    "    pylab.figure(1, dpi=1080)\n",
    "    pylab.xlabel(r\"Fraction of vertices removed ($\\rho$)\")\n",
    "    pylab.ylabel(r\"Fractional size of largest component ($\\sigma$)\")\n",
    "else:\n",
    "    pylab.figure(1, dpi=1080)\n",
    "    pylab.xlabel(r\"Fraction of vertices removed ($\\rho$)\")\n",
    "    pylab.ylabel(r\"Average path length ($\\sigma$)\")\n",
    "\n",
    "pylab.plot(x1, y1, \"b-\", alpha=0.6, linewidth=2.0)\n",
    "pylab.plot(x2, y2, \"g-\", alpha=0.6, linewidth=2.0)\n",
    "pylab.plot(x3, y3, \"r-\", alpha=0.6, linewidth=2.0)\n",
    "pylab.plot(x5, y5, \"k-\", alpha=0.6, linewidth=2.0)\n",
    "\n",
    "# Generate csv file\n",
    "import numpy as np\n",
    "\n",
    "pylab.legend((r\"Degree ($R = %4.3f$)\" % vd,\n",
    "              \"Betweenness ($R = %4.3f$)\" % vb,\n",
    "              \"Closeness ($R = %4.3f$)\" % vc,\n",
    "              \"Random ($R = %4.3f$)\" % vr),\n",
    "            loc=\"upper right\", shadow=False)\n",
    "\n",
    "pylab.savefig(outfile, format=\"png\")\n",
    "pylab.close(1)\n",
    "\n",
    "matrix = np.matrix([x1, y1, y2, y3, y5])\n",
    "filename = outfile.rsplit(\".\", 1)[0] + \".csv\"\n",
    "header = \" , degree, betweeness, closeness, random\"\n",
    "separator = \", \"\n",
    "\n",
    "np.savetxt(filename, matrix.transpose(), fmt=\"%2.5f\", delimiter=separator,header=header, comments=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apl=True\n",
    "\n",
    "if apl==True:\n",
    "    analysis_method = robustness_analysis_apl\n",
    "    method='apl'\n",
    "else:\n",
    "    analysis_method = robustness_analysis\n",
    "    method='com'\n",
    "        \n",
    "outfile='data_indicator/Milano/Robustness/part2/part2_b20_{}.png'.format(method)\n",
    "\n",
    "recalculate=False\n",
    "\n",
    "g = ox.utils_graph.get_digraph(G_20_16, weight='length')\n",
    "g = g.to_undirected()\n",
    "#g = ox.utils_graph.get_undirected(G_bspf)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x1, y1, vd = analysis_method(g.copy(), nx.degree_centrality, recalculate)\n",
    "x2, y2, vb = analysis_method(g.copy(), nx.betweenness_centrality, recalculate)\n",
    "x3, y3, vc = analysis_method(g.copy(), nx.closeness_centrality, recalculate)\n",
    "x5, y5, vr = analysis_method(g.copy(), random_ranking)\n",
    "\n",
    "if not apl:\n",
    "    pylab.figure(1, dpi=1080)\n",
    "    pylab.xlabel(r\"Fraction of vertices removed ($\\rho$)\")\n",
    "    pylab.ylabel(r\"Fractional size of largest component ($\\sigma$)\")\n",
    "else:\n",
    "    pylab.figure(1, dpi=1080)\n",
    "    pylab.xlabel(r\"Fraction of vertices removed ($\\rho$)\")\n",
    "    pylab.ylabel(r\"Average path length ($\\sigma$)\")\n",
    "\n",
    "pylab.plot(x1, y1, \"b-\", alpha=0.6, linewidth=2.0)\n",
    "pylab.plot(x2, y2, \"g-\", alpha=0.6, linewidth=2.0)\n",
    "pylab.plot(x3, y3, \"r-\", alpha=0.6, linewidth=2.0)\n",
    "pylab.plot(x5, y5, \"k-\", alpha=0.6, linewidth=2.0)\n",
    "\n",
    "# Generate csv file\n",
    "import numpy as np\n",
    "\n",
    "pylab.legend((r\"Degree ($R = %4.3f$)\" % vd,\n",
    "              \"Betweenness ($R = %4.3f$)\" % vb,\n",
    "              \"Closeness ($R = %4.3f$)\" % vc,\n",
    "              \"Random ($R = %4.3f$)\" % vr),\n",
    "            loc=\"upper right\", shadow=False)\n",
    "\n",
    "pylab.savefig(outfile, format=\"png\")\n",
    "pylab.close(1)\n",
    "\n",
    "matrix = np.matrix([x1, y1, y2, y3, y5])\n",
    "filename = outfile.rsplit(\".\", 1)[0] + \".csv\"\n",
    "header = \" , degree, betweeness, closeness, random\"\n",
    "separator = \", \"\n",
    "\n",
    "np.savetxt(filename, matrix.transpose(), fmt=\"%2.5f\", delimiter=separator,header=header, comments=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apl=False\n",
    "\n",
    "if apl==True:\n",
    "    analysis_method = robustness_analysis_apl\n",
    "    method='apl'\n",
    "else:\n",
    "    analysis_method = robustness_analysis\n",
    "    method='com'\n",
    "        \n",
    "outfile='data_indicator/Milano/Robustness/part2/part2_b21_{}.png'.format(method)\n",
    "\n",
    "recalculate=False\n",
    "\n",
    "g = ox.utils_graph.get_digraph(G_21_16, weight='length')\n",
    "g = g.to_undirected()\n",
    "#g = ox.utils_graph.get_undirected(G_bspf)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x1, y1, vd = analysis_method(g.copy(), nx.degree_centrality, recalculate)\n",
    "x2, y2, vb = analysis_method(g.copy(), nx.betweenness_centrality, recalculate)\n",
    "x3, y3, vc = analysis_method(g.copy(), nx.closeness_centrality, recalculate)\n",
    "x5, y5, vr = analysis_method(g.copy(), random_ranking)\n",
    "\n",
    "if not apl:\n",
    "    pylab.figure(1, dpi=1080)\n",
    "    pylab.xlabel(r\"Fraction of vertices removed ($\\rho$)\")\n",
    "    pylab.ylabel(r\"Fractional size of largest component ($\\sigma$)\")\n",
    "else:\n",
    "    pylab.figure(1, dpi=1080)\n",
    "    pylab.xlabel(r\"Fraction of vertices removed ($\\rho$)\")\n",
    "    pylab.ylabel(r\"Average path length ($\\sigma$)\")\n",
    "\n",
    "pylab.plot(x1, y1, \"b-\", alpha=0.6, linewidth=2.0)\n",
    "pylab.plot(x2, y2, \"g-\", alpha=0.6, linewidth=2.0)\n",
    "pylab.plot(x3, y3, \"r-\", alpha=0.6, linewidth=2.0)\n",
    "pylab.plot(x5, y5, \"k-\", alpha=0.6, linewidth=2.0)\n",
    "\n",
    "# Generate csv file\n",
    "import numpy as np\n",
    "\n",
    "pylab.legend((r\"Degree ($R = %4.3f$)\" % vd,\n",
    "              \"Betweenness ($R = %4.3f$)\" % vb,\n",
    "              \"Closeness ($R = %4.3f$)\" % vc,\n",
    "              \"Random ($R = %4.3f$)\" % vr),\n",
    "            loc=\"upper right\", shadow=False)\n",
    "\n",
    "pylab.savefig(outfile, format=\"png\")\n",
    "pylab.close(1)\n",
    "\n",
    "matrix = np.matrix([x1, y1, y2, y3, y5])\n",
    "filename = outfile.rsplit(\".\", 1)[0] + \".csv\"\n",
    "header = \" , degree, betweeness, closeness, random\"\n",
    "separator = \", \"\n",
    "\n",
    "np.savetxt(filename, matrix.transpose(), fmt=\"%2.5f\", delimiter=separator,header=header, comments=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apl=False\n",
    "\n",
    "if apl==True:\n",
    "    analysis_method = robustness_analysis_apl\n",
    "    method='apl'\n",
    "else:\n",
    "    analysis_method = robustness_analysis\n",
    "    method='com'\n",
    "        \n",
    "outfile='data_indicator/Milano/Robustness/part2/part2_b20_{}.png'.format(method)\n",
    "\n",
    "recalculate=False\n",
    "\n",
    "g = ox.utils_graph.get_digraph(G_20_16, weight='length')\n",
    "g = g.to_undirected()\n",
    "#g = ox.utils_graph.get_undirected(G_bspf)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x1, y1, vd = analysis_method(g.copy(), nx.degree_centrality, recalculate)\n",
    "x2, y2, vb = analysis_method(g.copy(), nx.betweenness_centrality, recalculate)\n",
    "x3, y3, vc = analysis_method(g.copy(), nx.closeness_centrality, recalculate)\n",
    "x5, y5, vr = analysis_method(g.copy(), random_ranking)\n",
    "\n",
    "if not apl:\n",
    "    pylab.figure(1, dpi=1080)\n",
    "    pylab.xlabel(r\"Fraction of vertices removed ($\\rho$)\")\n",
    "    pylab.ylabel(r\"Fractional size of largest component ($\\sigma$)\")\n",
    "else:\n",
    "    pylab.figure(1, dpi=1080)\n",
    "    pylab.xlabel(r\"Fraction of vertices removed ($\\rho$)\")\n",
    "    pylab.ylabel(r\"Average path length ($\\sigma$)\")\n",
    "\n",
    "pylab.plot(x1, y1, \"b-\", alpha=0.6, linewidth=2.0)\n",
    "pylab.plot(x2, y2, \"g-\", alpha=0.6, linewidth=2.0)\n",
    "pylab.plot(x3, y3, \"r-\", alpha=0.6, linewidth=2.0)\n",
    "pylab.plot(x5, y5, \"k-\", alpha=0.6, linewidth=2.0)\n",
    "\n",
    "# Generate csv file\n",
    "import numpy as np\n",
    "\n",
    "pylab.legend((r\"Degree ($R = %4.3f$)\" % vd,\n",
    "              \"Betweenness ($R = %4.3f$)\" % vb,\n",
    "              \"Closeness ($R = %4.3f$)\" % vc,\n",
    "              \"Random ($R = %4.3f$)\" % vr),\n",
    "            loc=\"upper right\", shadow=False)\n",
    "\n",
    "pylab.savefig(outfile, format=\"png\")\n",
    "pylab.close(1)\n",
    "\n",
    "matrix = np.matrix([x1, y1, y2, y3, y5])\n",
    "filename = outfile.rsplit(\".\", 1)[0] + \".csv\"\n",
    "header = \" , degree, betweeness, closeness, random\"\n",
    "separator = \", \"\n",
    "\n",
    "np.savetxt(filename, matrix.transpose(), fmt=\"%2.5f\", delimiter=separator,header=header, comments=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
