{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import operator\n",
    "import pylab\n",
    "import random\n",
    "import sys\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import osmnx as ox\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as colors\n",
    "from IPython.display import Image\n",
    "from pprint import pprint\n",
    "import folium\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robustness_analysis(g, node_classifier, recalculate=False):\n",
    "    m = node_classifier(g)\n",
    "    l = sorted(m.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    x = []\n",
    "    y = []\n",
    "    \n",
    "    \n",
    "    sbg = [g.subgraph(c).copy() for c in nx.connected_components(g)]\n",
    "    largest_component = max(sbg, key=lambda c: sum(d[\"length\"] for u, v, d in c.edges(data=True)))\n",
    "    \n",
    "    \n",
    "    n = len(g.nodes())\n",
    "    tl=sum(d[\"length\"] for u, v, d in g.edges(data=True))\n",
    "    x.append(0)\n",
    "    y.append(sum(d[\"length\"] for u, v, d in largest_component.edges(data=True)) * 1. / tl)\n",
    "    r = 0.0\n",
    "    for i in range(1, n-1):\n",
    "        g.remove_node(l.pop(0)[0])\n",
    "        if recalculate:\n",
    "            m = node_classifier(g)\n",
    "            l = sorted(m.items(), key=operator.itemgetter(1),reverse=True)\n",
    "            \n",
    "        sbg = [g.subgraph(c).copy() for c in nx.connected_components(g)]\n",
    "        largest_component = max(sbg, key=lambda c: sum(d[\"length\"] for u, v, d in c.edges(data=True)))        \n",
    "        x.append(i * 1. / n)\n",
    "        r += sum(d[\"length\"] for u, v, d in largest_component.edges(data=True)) * 1. / tl\n",
    "        y.append(sum(d[\"length\"] for u, v, d in largest_component.edges(data=True)) * 1. / tl)\n",
    "    print(r,tl,n)\n",
    "    return x, y, r / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robustness_analysis_apl(g, node_classifier, recalculate=False):\n",
    "    m = node_classifier(g)\n",
    "    l = sorted(m.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    average_path_length = 0.0\n",
    "    number_of_components = 0\n",
    "    n = len(g.nodes())\n",
    "    \n",
    "    \n",
    "    \n",
    "    sbg = [g.subgraph(c).copy() for c in nx.connected_components(g)]\n",
    "    for sg in sbg:\n",
    "        average_path_length += nx.average_shortest_path_length(sg)\n",
    "        number_of_components += 1\n",
    "\n",
    "    average_path_length = average_path_length / number_of_components\n",
    "    initial_apl = average_path_length\n",
    "\n",
    "    x.append(0)\n",
    "    y.append(average_path_length * 1. / initial_apl)\n",
    "    r = 0.0\n",
    "    for i in range(1, n-1):\n",
    "        g.remove_node(l.pop(0)[0])\n",
    "        if recalculate:\n",
    "            m = node_classifier(g)\n",
    "            l = sorted(m.items(), key=operator.itemgetter(1),\n",
    "                       reverse=True)\n",
    "\n",
    "        average_path_length = 0.0\n",
    "        number_of_components = 0\n",
    "\n",
    "        \n",
    "        \n",
    "        sbg = [g.subgraph(c).copy() for c in nx.connected_components(g)]\n",
    "        for sg in sbg:\n",
    "            if len(sg.nodes()) > 1:\n",
    "                average_path_length += nx.average_shortest_path_length(sg)\n",
    "            number_of_components += 1\n",
    "\n",
    "        average_path_length = average_path_length / number_of_components\n",
    "\n",
    "        x.append(i * 1. / n)\n",
    "        r += average_path_length * 1. / initial_apl\n",
    "        y.append(average_path_length * 1. / initial_apl)\n",
    "    return x, y, r / n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def random_ranking(g):\n",
    "    nodes = g.nodes()\n",
    "    values = g.nodes()\n",
    "    values = list(values)\n",
    "    random.shuffle(values)    \n",
    "    \n",
    "    return dict(zip(nodes, values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network getting\n",
    "\n",
    "# get 2021-04-01 bike networks(.graphml file and .png file) of Roma\n",
    "\n",
    "\n",
    "ox.config(overpass_settings='[out:json][timeout:180][date:\"2021-04-01T00:00:00Z\"]')\n",
    "\n",
    "place = 'Roma, Italy'\n",
    "\n",
    "cf1 = '[\"highway\"~\"cycleway\"][\"bicycle\"!~\"no\"]'\n",
    "cf2 = '[\"cycleway\"][\"cycleway\"!~\"no\"]'\n",
    "cf3 = '[\"cycleway:right\"][\"cycleway:right\"!~\"no\"]'\n",
    "cf4 = '[\"cycleway:left\"][\"cycleway:left\"!~\"no\"]'\n",
    "cf5 = '[\"cycleway:both\"][\"cycleway:both\"!~\"no\"]'\n",
    "cf6 = '[\"bicycle\"~\"designated\"]'\n",
    "cf7 = '[\"oneway:bicycle\"]'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "G_21_b1=ox.graph.graph_from_place(place, simplify=False, retain_all=True, \n",
    "                                  truncate_by_edge=True, which_result=None, buffer_dist=None, clean_periphery=True, \n",
    "                                  custom_filter = cf1)\n",
    "G_21_b2=ox.graph.graph_from_place(place, simplify=False, retain_all=True, \n",
    "                                  truncate_by_edge=True, which_result=None, buffer_dist=None, clean_periphery=True, \n",
    "                                  custom_filter = cf2)\n",
    "G_21_b3=ox.graph.graph_from_place(place, simplify=False, retain_all=True, \n",
    "                                  truncate_by_edge=True, which_result=None, buffer_dist=None, clean_periphery=True, \n",
    "                                  custom_filter = cf3)\n",
    "G_21_b4=ox.graph.graph_from_place(place, simplify=False, retain_all=True, \n",
    "                                  truncate_by_edge=True, which_result=None, buffer_dist=None, clean_periphery=True, \n",
    "                                  custom_filter = cf4)\n",
    "G_21_b5=ox.graph.graph_from_place(place, simplify=False, retain_all=True, \n",
    "                                  truncate_by_edge=True, which_result=None, buffer_dist=None, clean_periphery=True, \n",
    "                                  custom_filter = cf5)\n",
    "G_21_b6=ox.graph.graph_from_place(place, simplify=False, retain_all=True, \n",
    "                                  truncate_by_edge=True, which_result=None, buffer_dist=None, clean_periphery=True, \n",
    "                                  custom_filter = cf6)\n",
    "G_21_b7=ox.graph.graph_from_place(place, simplify=False, retain_all=True, \n",
    "                                  truncate_by_edge=True, which_result=None, buffer_dist=None, clean_periphery=True, \n",
    "                                  custom_filter = cf7)\n",
    "\n",
    "G_21_b11 = nx.compose(G_21_b1,  G_21_b2)\n",
    "G_21_b12 = nx.compose(G_21_b11, G_21_b3)\n",
    "G_21_b13 = nx.compose(G_21_b12, G_21_b4)\n",
    "G_21_b14 = nx.compose(G_21_b13, G_21_b5)\n",
    "G_21_b15 = nx.compose(G_21_b14, G_21_b6)\n",
    "G_21_16 = nx.compose(G_21_b15, G_21_b7)\n",
    "G_21_16 = ox.simplification.simplify_graph(G_21_16)\n",
    "\n",
    "\n",
    "G_21_21 = ox.simplification.consolidate_intersections(ox.project_graph(G_21_16,to_crs='EPSG:3812'), tolerance=15, rebuild_graph=True, dead_ends=True, reconnect_edges=True)\n",
    "G_21_22 = ox.project_graph(G_21_21, to_crs='EPSG:4326')\n",
    "\n",
    "fig, axb2 = ox.plot_graph(G_21_22, node_size=0,bgcolor='black',edge_color='white',edge_linewidth=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network getting\n",
    "\n",
    "# get 2020-01-01 bike networks(.graphml file and .png file) of Roma\n",
    "\n",
    "\n",
    "ox.config(overpass_settings='[out:json][timeout:180][date:\"2020-01-01T00:00:00Z\"]')\n",
    "\n",
    "place = 'Roma, Italy'\n",
    "\n",
    "cf1 = '[\"highway\"~\"cycleway\"][\"bicycle\"!~\"no\"]'\n",
    "cf2 = '[\"cycleway\"][\"cycleway\"!~\"no\"]'\n",
    "cf3 = '[\"cycleway:right\"][\"cycleway:right\"!~\"no\"]'\n",
    "cf4 = '[\"cycleway:left\"][\"cycleway:left\"!~\"no\"]'\n",
    "cf5 = '[\"cycleway:both\"][\"cycleway:both\"!~\"no\"]'\n",
    "cf6 = '[\"bicycle\"~\"designated\"]'\n",
    "cf7 = '[\"oneway:bicycle\"]'\n",
    "\n",
    "\n",
    "\n",
    "G_20_b1=ox.graph.graph_from_place(place, simplify=False, retain_all=True, \n",
    "                                  truncate_by_edge=True, which_result=None, buffer_dist=None, clean_periphery=True, \n",
    "                                  custom_filter = cf1)\n",
    "G_20_b2=ox.graph.graph_from_place(place, simplify=False, retain_all=True, \n",
    "                                  truncate_by_edge=True, which_result=None, buffer_dist=None, clean_periphery=True, \n",
    "                                  custom_filter = cf2)\n",
    "G_20_b3=ox.graph.graph_from_place(place, simplify=False, retain_all=True, \n",
    "                                  truncate_by_edge=True, which_result=None, buffer_dist=None, clean_periphery=True, \n",
    "                                  custom_filter = cf3)\n",
    "\n",
    "\n",
    "G_20_b6=ox.graph.graph_from_place(place, simplify=False, retain_all=True, \n",
    "                                  truncate_by_edge=True, which_result=None, buffer_dist=None, clean_periphery=True, \n",
    "                                  custom_filter = cf6)\n",
    "G_20_b7=ox.graph.graph_from_place(place, simplify=False, retain_all=True, \n",
    "                                  truncate_by_edge=True, which_result=None, buffer_dist=None, clean_periphery=True, \n",
    "                                  custom_filter = cf7)\n",
    "\n",
    "G_20_b11 = nx.compose(G_20_b1,  G_20_b2)\n",
    "G_20_b12 = nx.compose(G_20_b11, G_20_b3)\n",
    "G_20_b15 = nx.compose(G_20_b12, G_20_b6)\n",
    "G_20_16 = nx.compose(G_20_b15, G_20_b7)\n",
    "G_20_16 = ox.simplification.simplify_graph(G_20_16)\n",
    "\n",
    "\n",
    "G_20_21 = ox.simplification.consolidate_intersections(ox.project_graph(G_20_16,to_crs='EPSG:3812'), tolerance=15, rebuild_graph=True, dead_ends=True, reconnect_edges=True)\n",
    "G_20_22 = ox.project_graph(G_20_21, to_crs='EPSG:4326')\n",
    "\n",
    "fig, axb2 = ox.plot_graph(G_20_22, node_size=0,bgcolor='black',edge_color='white',edge_linewidth=0.5)\n",
    "\n",
    "print('Roma 20_bike_net saved')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apl=True\n",
    "\n",
    "if apl==True:\n",
    "    analysis_method = robustness_analysis_apl\n",
    "    method='apl'\n",
    "else:\n",
    "    analysis_method = robustness_analysis\n",
    "    method='com'\n",
    "        \n",
    "outfile='data_indicator/Roma/Robustness/part1/part1_b21_{}.png'.format(method)\n",
    "\n",
    "recalculate=False\n",
    "\n",
    "g = ox.utils_graph.get_digraph(G_21_22, weight='length')\n",
    "g = g.to_undirected()\n",
    "#g = ox.utils_graph.get_undirected(G_bspf)\n",
    "\n",
    "\n",
    "x1, y1, vd = analysis_method(g.copy(), nx.degree_centrality, recalculate)\n",
    "x2, y2, vb = analysis_method(g.copy(), nx.betweenness_centrality, recalculate)\n",
    "x3, y3, vc = analysis_method(g.copy(), nx.closeness_centrality, recalculate)\n",
    "x5, y5, vr = analysis_method(g.copy(), random_ranking)\n",
    "\n",
    "if not apl:\n",
    "    pylab.figure(1, dpi=1080)\n",
    "    pylab.xlabel(r\"Fraction of vertices removed ($\\rho$)\")\n",
    "    pylab.ylabel(r\"Fractional size of largest component ($\\sigma$)\")\n",
    "else:\n",
    "    pylab.figure(1, dpi=1080)\n",
    "    pylab.xlabel(r\"Fraction of vertices removed ($\\rho$)\")\n",
    "    pylab.ylabel(r\"Average path length ($\\sigma$)\")\n",
    "\n",
    "pylab.plot(x1, y1, \"b-\", alpha=0.6, linewidth=2.0)\n",
    "pylab.plot(x2, y2, \"g-\", alpha=0.6, linewidth=2.0)\n",
    "pylab.plot(x3, y3, \"r-\", alpha=0.6, linewidth=2.0)\n",
    "pylab.plot(x5, y5, \"k-\", alpha=0.6, linewidth=2.0)\n",
    "\n",
    "# Generate csv file\n",
    "import numpy as np\n",
    "\n",
    "pylab.legend((r\"Degree ($R = %4.3f$)\" % vd,\n",
    "              \"Betweenness ($R = %4.3f$)\" % vb,\n",
    "              \"Closeness ($R = %4.3f$)\" % vc,\n",
    "              \"Random ($R = %4.3f$)\" % vr),\n",
    "            loc=\"upper right\", shadow=False)\n",
    "\n",
    "pylab.savefig(outfile, format=\"png\")\n",
    "pylab.close(1)\n",
    "\n",
    "matrix = np.matrix([x1, y1, y2, y3, y5])\n",
    "filename = outfile.rsplit(\".\", 1)[0] + \".csv\"\n",
    "header = \" , degree, betweeness, closeness, random\"\n",
    "separator = \", \"\n",
    "\n",
    "np.savetxt(filename, matrix.transpose(), fmt=\"%2.5f\", delimiter=separator,header=header, comments=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apl=True\n",
    "\n",
    "if apl==True:\n",
    "    analysis_method = robustness_analysis_apl\n",
    "    method='apl'\n",
    "else:\n",
    "    analysis_method = robustness_analysis\n",
    "    method='com'\n",
    "        \n",
    "outfile='data_indicator/Roma/Robustness/part1/part1_b20_{}.png'.format(method)\n",
    "\n",
    "recalculate=False\n",
    "\n",
    "g = ox.utils_graph.get_digraph(G_20_22, weight='length')\n",
    "g = g.to_undirected()\n",
    "#g = ox.utils_graph.get_undirected(G_bspf)\n",
    "\n",
    "\n",
    "x1, y1, vd = analysis_method(g.copy(), nx.degree_centrality, recalculate)\n",
    "x2, y2, vb = analysis_method(g.copy(), nx.betweenness_centrality, recalculate)\n",
    "x3, y3, vc = analysis_method(g.copy(), nx.closeness_centrality, recalculate)\n",
    "x5, y5, vr = analysis_method(g.copy(), random_ranking)\n",
    "\n",
    "if not apl:\n",
    "    pylab.figure(1, dpi=1080)\n",
    "    pylab.xlabel(r\"Fraction of vertices removed ($\\rho$)\")\n",
    "    pylab.ylabel(r\"Fractional size of largest component ($\\sigma$)\")\n",
    "else:\n",
    "    pylab.figure(1, dpi=1080)\n",
    "    pylab.xlabel(r\"Fraction of vertices removed ($\\rho$)\")\n",
    "    pylab.ylabel(r\"Average path length ($\\sigma$)\")\n",
    "\n",
    "pylab.plot(x1, y1, \"b-\", alpha=0.6, linewidth=2.0)\n",
    "pylab.plot(x2, y2, \"g-\", alpha=0.6, linewidth=2.0)\n",
    "pylab.plot(x3, y3, \"r-\", alpha=0.6, linewidth=2.0)\n",
    "pylab.plot(x5, y5, \"k-\", alpha=0.6, linewidth=2.0)\n",
    "\n",
    "# Generate csv file\n",
    "import numpy as np\n",
    "\n",
    "pylab.legend((r\"Degree ($R = %4.3f$)\" % vd,\n",
    "              \"Betweenness ($R = %4.3f$)\" % vb,\n",
    "              \"Closeness ($R = %4.3f$)\" % vc,\n",
    "              \"Random ($R = %4.3f$)\" % vr),\n",
    "            loc=\"upper right\", shadow=False)\n",
    "\n",
    "pylab.savefig(outfile, format=\"png\")\n",
    "pylab.close(1)\n",
    "\n",
    "matrix = np.matrix([x1, y1, y2, y3, y5])\n",
    "filename = outfile.rsplit(\".\", 1)[0] + \".csv\"\n",
    "header = \" , degree, betweeness, closeness, random\"\n",
    "separator = \", \"\n",
    "\n",
    "np.savetxt(filename, matrix.transpose(), fmt=\"%2.5f\", delimiter=separator,header=header, comments=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apl=False\n",
    "\n",
    "if apl==True:\n",
    "    analysis_method = robustness_analysis_apl\n",
    "    method='apl'\n",
    "else:\n",
    "    analysis_method = robustness_analysis\n",
    "    method='com'\n",
    "        \n",
    "outfile='data_indicator/Roma/Robustness/part1/part1_b21_{}.png'.format(method)\n",
    "\n",
    "recalculate=False\n",
    "\n",
    "g = ox.utils_graph.get_digraph(G_21_22, weight='length')\n",
    "g = g.to_undirected()\n",
    "#g = ox.utils_graph.get_undirected(G_bspf)\n",
    "\n",
    "\n",
    "x1, y1, vd = analysis_method(g.copy(), nx.degree_centrality, recalculate)\n",
    "x2, y2, vb = analysis_method(g.copy(), nx.betweenness_centrality, recalculate)\n",
    "x3, y3, vc = analysis_method(g.copy(), nx.closeness_centrality, recalculate)\n",
    "x5, y5, vr = analysis_method(g.copy(), random_ranking)\n",
    "\n",
    "if not apl:\n",
    "    pylab.figure(1, dpi=1080)\n",
    "    pylab.xlabel(r\"Fraction of vertices removed ($\\rho$)\")\n",
    "    pylab.ylabel(r\"Fractional size of largest component ($\\sigma$)\")\n",
    "else:\n",
    "    pylab.figure(1, dpi=1080)\n",
    "    pylab.xlabel(r\"Fraction of vertices removed ($\\rho$)\")\n",
    "    pylab.ylabel(r\"Average path length ($\\sigma$)\")\n",
    "\n",
    "pylab.plot(x1, y1, \"b-\", alpha=0.6, linewidth=2.0)\n",
    "pylab.plot(x2, y2, \"g-\", alpha=0.6, linewidth=2.0)\n",
    "pylab.plot(x3, y3, \"r-\", alpha=0.6, linewidth=2.0)\n",
    "pylab.plot(x5, y5, \"k-\", alpha=0.6, linewidth=2.0)\n",
    "\n",
    "# Generate csv file\n",
    "import numpy as np\n",
    "\n",
    "pylab.legend((r\"Degree ($R = %4.3f$)\" % vd,\n",
    "              \"Betweenness ($R = %4.3f$)\" % vb,\n",
    "              \"Closeness ($R = %4.3f$)\" % vc,\n",
    "              \"Random ($R = %4.3f$)\" % vr),\n",
    "            loc=\"upper right\", shadow=False)\n",
    "\n",
    "pylab.savefig(outfile, format=\"png\")\n",
    "pylab.close(1)\n",
    "\n",
    "matrix = np.matrix([x1, y1, y2, y3, y5])\n",
    "filename = outfile.rsplit(\".\", 1)[0] + \".csv\"\n",
    "header = \" , degree, betweeness, closeness, random\"\n",
    "separator = \", \"\n",
    "\n",
    "np.savetxt(filename, matrix.transpose(), fmt=\"%2.5f\", delimiter=separator,header=header, comments=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apl=False\n",
    "\n",
    "if apl==True:\n",
    "    analysis_method = robustness_analysis_apl\n",
    "    method='apl'\n",
    "else:\n",
    "    analysis_method = robustness_analysis\n",
    "    method='com'\n",
    "        \n",
    "outfile='data_indicator/Roma/Robustness/part1/part1_b20_{}.png'.format(method)\n",
    "\n",
    "recalculate=False\n",
    "\n",
    "g = ox.utils_graph.get_digraph(G_20_22, weight='length')\n",
    "g = g.to_undirected()\n",
    "#g = ox.utils_graph.get_undirected(G_bspf)\n",
    "\n",
    "\n",
    "x1, y1, vd = analysis_method(g.copy(), nx.degree_centrality, recalculate)\n",
    "x2, y2, vb = analysis_method(g.copy(), nx.betweenness_centrality, recalculate)\n",
    "x3, y3, vc = analysis_method(g.copy(), nx.closeness_centrality, recalculate)\n",
    "x5, y5, vr = analysis_method(g.copy(), random_ranking)\n",
    "\n",
    "if not apl:\n",
    "    pylab.figure(1, dpi=1080)\n",
    "    pylab.xlabel(r\"Fraction of vertices removed ($\\rho$)\")\n",
    "    pylab.ylabel(r\"Fractional size of largest component ($\\sigma$)\")\n",
    "else:\n",
    "    pylab.figure(1, dpi=1080)\n",
    "    pylab.xlabel(r\"Fraction of vertices removed ($\\rho$)\")\n",
    "    pylab.ylabel(r\"Average path length ($\\sigma$)\")\n",
    "\n",
    "pylab.plot(x1, y1, \"b-\", alpha=0.6, linewidth=2.0)\n",
    "pylab.plot(x2, y2, \"g-\", alpha=0.6, linewidth=2.0)\n",
    "pylab.plot(x3, y3, \"r-\", alpha=0.6, linewidth=2.0)\n",
    "pylab.plot(x5, y5, \"k-\", alpha=0.6, linewidth=2.0)\n",
    "\n",
    "# Generate csv file\n",
    "import numpy as np\n",
    "\n",
    "pylab.legend((r\"Degree ($R = %4.3f$)\" % vd,\n",
    "              \"Betweenness ($R = %4.3f$)\" % vb,\n",
    "              \"Closeness ($R = %4.3f$)\" % vc,\n",
    "              \"Random ($R = %4.3f$)\" % vr),\n",
    "            loc=\"upper right\", shadow=False)\n",
    "\n",
    "pylab.savefig(outfile, format=\"png\")\n",
    "pylab.close(1)\n",
    "\n",
    "matrix = np.matrix([x1, y1, y2, y3, y5])\n",
    "filename = outfile.rsplit(\".\", 1)[0] + \".csv\"\n",
    "header = \" , degree, betweeness, closeness, random\"\n",
    "separator = \", \"\n",
    "\n",
    "np.savetxt(filename, matrix.transpose(), fmt=\"%2.5f\", delimiter=separator,header=header, comments=\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
